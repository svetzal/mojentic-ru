[package]
name = "mojentic"
version = "1.0.0"
edition = "2021"
authors = ["Stacey Vetzal <stacey@vetzal.com>"]
description = "An LLM integration framework for Rust"
license = "MIT"
repository = "https://github.com/svetzal/mojentic-ru"
homepage = "https://svetzal.github.io/mojentic-ru"
documentation = "https://svetzal.github.io/mojentic-ru/api/mojentic"
readme = "README.md"
keywords = ["llm", "ai", "ollama", "openai", "agents"]
categories = ["api-bindings", "asynchronous"]

[dependencies]
# Core async runtime
tokio = { version = "1", features = ["full"] }
async-trait = "0.1"
futures-util = "0.3"
futures = "0.3"
async-stream = "0.3"

# HTTP client
reqwest = { version = "0.12", features = ["json", "stream"] }

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
schemars = "0.8"  # For JSON schema generation (Ollama structured output)

# Base64 encoding for images
base64 = "0.22"

# Error handling
thiserror = "1.0"
anyhow = "1.0"

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# UUID generation
uuid = { version = "1.0", features = ["v4", "serde"] }

# Date/time handling
chrono = "0.4"

# Tokenization
tiktoken-rs = "0.5"

# Environment variables
dotenv = "0.15"

# File operations
regex = "1.0"
glob = "0.3"

# HTML parsing for web search
scraper = "0.20"
urlencoding = "2.1"

[dev-dependencies]
mockito = "1.0"
tokio-test = "0.4"
tempfile = "3.0"
regex = "1.0"

[features]
default = ["ollama"]
ollama = []
openai = []
anthropic = []
full = ["openai", "ollama", "anthropic"]
